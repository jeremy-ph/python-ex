{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "s = 'No pain no gain'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "'pain' in s"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "s.split()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['No', 'pain', 'no', 'gain']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "s.split().index('gain')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "s.split()[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'pain'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "s.split()[2][::-1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'on'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "s = \"한글도 처리 가능\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "'처리' in s"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "s.split()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['한글도', '처리', '가능']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "s.split()[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'한글도'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "s = 'AbCdEfGh'\n",
    "str_lower = s.lower()\n",
    "str_upper = s.upper()\n",
    "print(str_lower, str_upper)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "abcdefgh ABCDEFGH\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "s = 'I visited UK from US on 22-09-20'\n",
    "print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I visited UK from US on 22-09-20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "new_s = s.replace(\"UK\", \"United Kingdom\").replace(\"US\", \"United States\").replace(\"-20\",\"-2020\")\n",
    "print(new_s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I visited United Kingdom from United States on 22-09-2020\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 정규 표현식\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "check = 'ab.'\n",
    "print(re.match(check, 'abc'))\n",
    "print(re.match(check, 'c'))\n",
    "print(re.match(check, 'ab'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_sre.SRE_Match object; span=(0, 3), match='abc'>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 일반 사용시간과 컴파일 사용시간 체크\n",
    "import time\n",
    "\n",
    "normal_s_time = time.time()\n",
    "r = 'ab.'\n",
    "for i in range(1000):\n",
    "    re.match(check, 'abc')\n",
    "print('일반 사용시 소요 시간: ', time.time() - normal_s_time)\n",
    "\n",
    "compile_s_time = time.time()\n",
    "r = re.compile('ab.')\n",
    "for i in range(1000):\n",
    "    r.match(check)\n",
    "print(\"컴파일 사용시 소요 시간: \", time.time() - compile_s_time)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "일반 사용시 소요 시간:  0.0027360916137695312\n",
      "컴파일 사용시 소요 시간:  0.001146554946899414\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# search - match와 다르게 문자열 전체 검사\n",
    "check = \"ab?\"\n",
    "\n",
    "print(re.search('a', check))\n",
    "print(re.match('kkkab', check))\n",
    "print(re.search('kkkab', check))\n",
    "print(re.match('ab', check))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_sre.SRE_Match object; span=(0, 1), match='a'>\n",
      "None\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 2), match='ab'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# split 정규표현식에 행당하는 문자열을 기준으로 문자열 나눔\n",
    "r = re.compile(' ')\n",
    "print(r.split('abc abbc abcbab'))\n",
    "\n",
    "r = re.compile('c')\n",
    "print(r.split('abc abbc abcbab'))\n",
    "\n",
    "r = re.compile('[1-9]')\n",
    "print(r.split('s1abc 2v3s 4sss 5s'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['abc', 'abbc', 'abcbab']\n",
      "['ab', ' abb', ' ab', 'bab']\n",
      "['s', 'abc ', 'v', 's ', 'sss ', 's']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# sub 정규 표현식과 일치하는 부분을 다른 무자열로 교체\n",
    "print(re.sub('[a-z]', 'abcdefg', '1'))\n",
    "\n",
    "print(re.sub('[^a-z]', 'abc defg', '1'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "abc defg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# findall 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 리스트로 반환\n",
    "print(re.findall('[\\d]', '1ab 2cd 3ef 4g')) # 숫자만\n",
    "\n",
    "print(re.findall('[\\W]', '!abcd@@#')) # 문자,숫자가 아닌 특수문자"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1', '2', '3', '4']\n",
      "['!', '@', '@', '#']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# finditer 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 iterator객체로 반환\n",
    "# iterator 객체를 이용하면 생성된 객체를 하나씩 자동으로 가져올 수 있는 처리가 간편함\n",
    "iter1 = re.finditer('[\\d]', '1ab 2cd 3ef 4g')\n",
    "print(iter1)\n",
    "for i in iter1:\n",
    "    print(i)\n",
    "\n",
    "iter2 = re.finditer('[\\W]', '!abcd@@#')\n",
    "print(iter2)\n",
    "for i in iter2:\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<callable_iterator object at 0x7fd741cd4ba8>\n",
      "<_sre.SRE_Match object; span=(0, 1), match='1'>\n",
      "<_sre.SRE_Match object; span=(4, 5), match='2'>\n",
      "<_sre.SRE_Match object; span=(8, 9), match='3'>\n",
      "<_sre.SRE_Match object; span=(12, 13), match='4'>\n",
      "<callable_iterator object at 0x7fd741cd49b0>\n",
      "<_sre.SRE_Match object; span=(0, 1), match='!'>\n",
      "<_sre.SRE_Match object; span=(5, 6), match='@'>\n",
      "<_sre.SRE_Match object; span=(6, 7), match='@'>\n",
      "<_sre.SRE_Match object; span=(7, 8), match='#'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "토큰화(Tokenization)\n",
    "\n",
    "* 특수문자에 대한 처리\n",
    "    * 단어에 일반적으로 사용되는 알파벳, 숫자와는 다르게 특수문자는 별도의 처리가 필요\n",
    "    * 일괄적으로 단어의 특ㄱ수문자를 제거하는 방법도 있지만 특수문자가 단어에 특별한 의미를 가질 때 이를 학습에 반영시키지 못할 수도 있음\n",
    "    * 특수문자에 대한 일괄적인 제거보다는 데이터의 특성을 파악하고, 처리를 하는 것이 중요\n",
    "\n",
    "* 특정 단어에 대한 토큰 분리 방법\n",
    "    * 한 단어지만 토큰으로 분라할 때 판단되는 문자들로 이루어진 we're United Kingdom 등의 단어는 어떻게 분리해야 할지 선택이 필요\n",
    "    * we're은 한 단어이나 분리해도 단어의 의미에 별 영향을 끼치진 않지만 United Kingdom은 두 단어가 모여 특정 의미를 가리켜 분리해선 안됨\n",
    "    * 사용자가 단어의 특성을 고려해 토큰을 분리하는 것이 학습에 유리\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 단어 토큰화\n",
    "#   파이썬 내장 함수인 split을 활용해 단어 토큰화\n",
    "#   공백을 기준으로 단어를 분리\n",
    "sentence = 'Time is gold'\n",
    "tokens = [x for x in sentence.split(' ')]\n",
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Time', 'is', 'gold']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 토큰화는 nltk 패키지의 tokenize 모듈을 사용해 손쉽게 구현 가능\n",
    "# 단어 토큰화는 word_tokenize() 함수를 사용해 구현 가능\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Time', 'is', 'gold']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 문장 토크화는 줄바꿈 문장('\\n')를 기준으로 문장을 분리\n",
    "sentences = 'The world is a beautiful book. \\nBut of little use to him who cannot read it.'\n",
    "print(sentences)\n",
    "\n",
    "tokens = [x for x in sentences.split('\\n')]\n",
    "tokens "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The world is a beautiful book. \n",
      "But of little use to him who cannot read it.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['The world is a beautiful book. ',\n",
       " 'But of little use to him who cannot read it.']"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 문장 토큰화는 sent_tokenize() 함수를 사용해 구현가능\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokens = sent_tokenize(sentences)\n",
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['The world is a beautiful book.',\n",
       " 'But of little use to him who cannot read it.']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}